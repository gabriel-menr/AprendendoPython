{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Até agora, já vimos os seguintes pontos:\n",
    "# Primeira coisa a se fazer ao receber uma base de dados:\n",
    "* Verificar a tabela\n",
    "* Verificar a quantidade/porcentagem de dados nulos por coluna\n",
    "* Verificar o tipo de dados das colunas\n",
    "* Verificar informações descritivas a respeito das colunas numéricas e textuais\n",
    "\n",
    "# Após estas verificações, devemos realizar o tratamento da base de dados:\n",
    "* Tratar os dados nulos:\n",
    "    * Excluir linhas;\n",
    "    * Excluir colunas;\n",
    "    * Substituir valores nulos por média, mediana ou moda;\n",
    "* v (Iremos ver hoje);\n",
    "* Normalizar a base de dados (Iremos ver hoje).\n",
    "\n",
    "#### Então, o que veremos hoje é a parte final do tratamento da base de dados antes de aplicar um modelo de aprendizado de máquina\n",
    "\n",
    "# 1 - Converter os valores textuais para valores numéricos\n",
    "Não sei se todos se lembram, mas ao vermos o conceito de rede neural artificial, vimos que os valores são multiplicados por pesos e, desta forma, não teria como multiplcar um texto pelo peso.\n",
    "\n",
    "Para resolver isto, nós iremos converter todos os valores textuais para números, por exemplo, todos os valores 'Sim' para 1 e os valores 'Não' para 0.\n",
    "\n",
    "Então, neste caso, já vamos utilizar a base de dados tratada, sem valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos a importação da biblioteca\n",
    "# que nos permite ler e manipular tabelas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idade             0\n",
       "emprego           0\n",
       "estado_civil      0\n",
       "educacao          0\n",
       "saldo_bancario    0\n",
       "possui_casa       0\n",
       "emprestimo        0\n",
       "dia               0\n",
       "mes               0\n",
       "duracao           0\n",
       "qtd_contato       0\n",
       "deposito          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Atribuimos a base de dados à variável df\n",
    "df = pd.read_csv('banco_aula_9.csv')\n",
    "\n",
    "# Apenas para verificar quantos valores núlos cada coluna possui\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O foco aqui é converter os valores das colunas object (Colunas com valores textuais) para valores numéricos.\n",
    "Para verificar quais as colunas são do tipo object, podemos usar a função info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11162 entries, 0 to 11161\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   idade           11162 non-null  int64 \n",
      " 1   emprego         11162 non-null  object\n",
      " 2   estado_civil    11162 non-null  object\n",
      " 3   educacao        11162 non-null  object\n",
      " 4   saldo_bancario  11162 non-null  int64 \n",
      " 5   possui_casa     11162 non-null  object\n",
      " 6   emprestimo      11162 non-null  object\n",
      " 7   dia             11162 non-null  int64 \n",
      " 8   mes             11162 non-null  object\n",
      " 9   duracao         11162 non-null  int64 \n",
      " 10  qtd_contato     11162 non-null  int64 \n",
      " 11  deposito        11162 non-null  object\n",
      "dtypes: int64(5), object(7)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isto, podemos verificar que as colunas emprego, estado_civil, educacao, possui_casa, emprestimo, mes e deposito são colunas que possuem valores textuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe as colunas com valores textuais\n",
    "df[['emprego', 'estado_civil', 'educacao', 'possui_casa', 'emprestimo', 'mes', 'deposito']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Como realizar a conversão de valores textuais para numéricos?\n",
    "\n",
    "Aqui existem duas abordagens principais.\n",
    "\n",
    "## A primeira é usar a função loc para selecionar o valor desejado e alterar para um número específico\n",
    "Nesta função, após realizar a substituição para os valores numéricos, é necessário que especifique que a coluna se tornou numérica\n",
    "\n",
    "Esta abordagem é boa para substituir 'yes' para 1, 'no' para 0, os mese pelos respectivos números...\n",
    "\n",
    "Pensando nesta primeira abordagem, podemos utilinar nas colunas educacao, possui_casa, emprestimo, mes e deposito.\n",
    "\n",
    "## A segunda abordagem é utilizada quando existem muitos valores textuais diferentes\n",
    "Esta abordagem exige uma outra biblioteca além do pandas, chamada `LabelEncoder`\n",
    "\n",
    "Pensando nesta segunda abordagem, podemos utilinar nas colunas emprego e estado_civil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quais os valores da coluna educacao\n",
    "df.educacao.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['educacao'] == 'unknown', 'educacao'] = 0\n",
    "df.loc[df['educacao'] == 'primary', 'educacao'] = 1 \n",
    "df.loc[df['educacao'] == 'secondary', 'educacao'] = 2\n",
    "df.loc[df['educacao'] == 'tertiary', 'educacao'] = 3\n",
    "\n",
    "# Converte a coluna para o tipo de dados numérico\n",
    "df['educacao'] = pd.to_numeric(df['educacao'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceba que colocamos valores intuitivos para substituir\n",
    "\n",
    "unknown para 0\n",
    "\n",
    "primary para 1\n",
    "\n",
    "secondary para 2\n",
    "\n",
    "tertiary para 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estas 3 colunas abaixo possuem somente os valores\n",
    "# yes e no, então podemos substituir estes valores\n",
    "# por 1 e 0, respectivamente\n",
    "df.loc[df['possui_casa'] == 'no', 'possui_casa'] = 0\n",
    "df.loc[df['possui_casa'] == 'yes', 'possui_casa'] = 1\n",
    "\n",
    "df.loc[df['emprestimo'] == 'no', 'emprestimo'] = 0\n",
    "df.loc[df['emprestimo'] == 'yes', 'emprestimo'] = 1\n",
    "\n",
    "df.loc[df['deposito'] == 'no', 'deposito'] = 0\n",
    "df.loc[df['deposito'] == 'yes', 'deposito'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repare que, mesmo após a substituição por valores numéricos,\n",
    "# As colunas continuam classificadas como object. \n",
    "df[['possui_casa', 'emprestimo', 'deposito']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para solucionar este problema, usamos a função pd.to_numeric() \n",
    "df['possui_casa'] = pd.to_numeric(df['possui_casa'])\n",
    "df['emprestimo'] = pd.to_numeric(df['emprestimo'])\n",
    "df['deposito'] = pd.to_numeric(df['deposito'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora as colunas são do tipo numérico int. \n",
    "df[['possui_casa', 'emprestimo', 'deposito']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica os valores da coluna mes\n",
    "df.mes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Irá converter cada mês para o respectivo valor numérico\n",
    "df.loc[df['mes'] == 'jan', 'mes'] = 1\n",
    "df.loc[df['mes'] == 'feb', 'mes'] = 2\n",
    "df.loc[df['mes'] == 'mar', 'mes'] = 3\n",
    "df.loc[df['mes'] == 'apr', 'mes'] = 4\n",
    "df.loc[df['mes'] == 'may', 'mes'] = 5\n",
    "df.loc[df['mes'] == 'jun', 'mes'] = 6\n",
    "df.loc[df['mes'] == 'jul', 'mes'] = 7\n",
    "df.loc[df['mes'] == 'aug', 'mes'] = 8\n",
    "df.loc[df['mes'] == 'sep', 'mes'] = 9\n",
    "df.loc[df['mes'] == 'oct', 'mes'] = 10\n",
    "df.loc[df['mes'] == 'nov', 'mes'] = 11\n",
    "df.loc[df['mes'] == 'dec', 'mes'] = 12\n",
    "\n",
    "# Define a coluna como valor numérico\n",
    "df['mes'] = pd.to_numeric(df['mes'])\n",
    "\n",
    "# Exibe o tipo de dados da coluna\n",
    "df[['mes']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ao verificar o tipo de dados de todas as colunas, encontramos que apenas as colunas emprego e estado_civil não são do tipo numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe as colunas com valores textuais\n",
    "df[['emprego', 'estado_civil']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Substituição dos valores textuais por numéricos com o LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro passo, importar a biblioteca necessária\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apenas no caso do bloco de código a cima der erro, \n",
    "# execute este bloco para instalar a biblioteca\n",
    "#!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamamos a função LabelEncoder e atribuimos à variável le \n",
    "le_emprego = LabelEncoder()\n",
    "\n",
    "# Converte todos os valores textuais para numéricos\n",
    "# Nas colunas emprego\n",
    "df['emprego'] = le_emprego.fit_transform(df['emprego'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_emprego.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamamos a função LabelEncoder e atribuimos à variável le \n",
    "le_estado_civil = LabelEncoder()\n",
    "\n",
    "# Converte todos os valores textuais para numéricos\n",
    "# Nas colunas estado_civil\n",
    "df['estado_civil'] = le_estado_civil.fit_transform(df['estado_civil'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_estado_civil.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['emprego','estado_civil']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importante\n",
    "Este método é mais simples, entretanto, ele não usa um critério para atribuir os valores numéricos, por isto, em alguns casos, é preferível utilizar o outro método"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando o tipo de dados das colunas\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Machine Learning: Classificação e Regressão\n",
    "\n",
    "#### 2.1. Classificação\n",
    "Na classificação, o objetivo é prever uma classe (ou categoria) para uma entrada específica. \n",
    "\n",
    "- **Exemplos**: \n",
    "  - Determinar se um e-mail é spam ou não spam.\n",
    "  - Classificar imagens de animais como cães, gatos ou pássaros.\n",
    "\n",
    "- **Tipos**:\n",
    "  - **Classificação Binária**: Apenas duas classes possíveis (por exemplo, Sim ou Não).\n",
    "  - **Classificação Multiclasse**: Mais de duas classes possíveis.\n",
    "\n",
    "#### 2.2. Regressão\n",
    "Na regressão, o objetivo é prever um valor contínuo (e não uma classe).\n",
    "\n",
    "- **Exemplos**: \n",
    "  - Prever o preço de uma casa com base em características como área, número de quartos, etc.\n",
    "  - Estimar a temperatura para o próximo dia com base em dados históricos.\n",
    "\n",
    "#### 2.3. X (Atributos ou Variáveis Independentes)\n",
    "- São as entradas do modelo. \n",
    "- Representam as características ou recursos que serão usados para fazer previsões.\n",
    "- **Exemplo**: Em um problema de previsão de preço de casa, os atributos podem incluir área da casa, número de quartos, número de banheiros, etc.\n",
    "\n",
    "#### 2.4. y (Alvo ou Variável Dependente)\n",
    "- É o que queremos prever ou estimar.\n",
    "- **Exemplo**: No contexto da previsão de preço de casa mencionado acima, o 'y' seria o preço da casa.\n",
    "\n",
    "**Observação**: A relação entre `X` e `y` é o que o modelo tenta aprender. Em termos simples, o modelo tenta entender como as variações em `X` podem prever ou explicar as variações em `y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna o dataframe sem a coluna especificada (retornando somente as colunas de atributos)\n",
    "df.drop('deposito', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A variável X recebe todas as colunas dos atributos\n",
    "X = df.drop('deposito', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna o dataframe somente com a coluna depósito (classe alvo)\n",
    "df[['deposito']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A variável y recebe a classe alvo\n",
    "y = df[['deposito']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separação de Dados e Normalização em Machine Learning\n",
    "\n",
    "## 3. Separação de Dados em Treinamento e Teste\n",
    "\n",
    "### 3.1 O que é?\n",
    "\n",
    "- **Dados de Treinamento (X_train, y_train)**: Dados usados para treinar o modelo. O modelo 'aprende' com esses dados.\n",
    "  \n",
    "- **Dados de Teste (X_test, y_test)**: Dados usados para avaliar a performance do modelo. Estes dados ajudam a entender como o modelo se comportará com novas entradas.\n",
    "\n",
    "### 3.2 Por que separar?\n",
    "\n",
    "- **Evitar Overfitting**: Treinar e testar com o mesmo conjunto de dados pode levar a um modelo que se comporta perfeitamente com os dados conhecidos, mas não generaliza bem para novos dados.\n",
    "\n",
    "- **Avaliação Justa**: Ao testar o modelo com dados nunca vistos por ele, conseguimos uma avaliação mais honesta de sua performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa os dados em treinamento e teste com 30% para teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ainda estamos lidando com tabelas pandas\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[0] + X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Normalização\n",
    "\n",
    "### 4.1 O que é?\n",
    "\n",
    "Normalização é o processo de redimensionar os atributos para que tenham uma escala similar. Isso é especialmente importante para algoritmos que dependem da magnitude dos valores, como SVM ou algoritmos de otimização baseados em gradiente.\n",
    "\n",
    "### 4.2 MinMax Scaler\n",
    "\n",
    "- **O que é**: Transforma os dados de modo que eles fiquem dentro de um intervalo definido (geralmente entre 0 e 1).\n",
    "  \n",
    "- **Fórmula**: (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "\n",
    "\n",
    "### 4.3 Por que usar `fit_transform` nos dados de treinamento e `transform` nos dados de teste?\n",
    "\n",
    "Vamos quebrar isso em partes:\n",
    "\n",
    "#### 4.3.1 O que o `fit_transform` faz?\n",
    "\n",
    "1. **Fit**: O método \"aprende\" os parâmetros necessários para a normalização. No caso do MinMax Scaler, ele identifica os valores mínimos e máximos dos dados de treinamento.\n",
    "\n",
    "2. **Transform**: Depois de aprender os parâmetros, o método aplica a normalização, ajustando os dados de acordo com a fórmula mencionada anteriormente.\n",
    "\n",
    "Portanto, quando aplicamos `fit_transform` aos dados de treinamento, estamos basicamente dizendo: \"Descubra os valores mínimos e máximos desses dados e, em seguida, use esses valores para ajustar a escala dos dados entre 0 e 1\".\n",
    "\n",
    "#### 4.3.2 E o `transform`?\n",
    "\n",
    "O método `transform` utiliza os valores mínimos e máximos já \"aprendidos\" (pelo `fit`) e aplica a normalização. Não \"reaprende\" os parâmetros.\n",
    "\n",
    "#### 4.3.3 Por que essa distinção é crucial?\n",
    "\n",
    "Imagine que você está tentando normalizar as temperaturas registradas durante um ano. Seus dados de treinamento contêm temperaturas dos primeiros 9 meses, e seus dados de teste contêm os últimos 3 meses.\n",
    "\n",
    "1. Ao usar `fit_transform` nos dados de treinamento, o MinMax Scaler pode determinar que a temperatura varia de 0°C a 30°C.\n",
    "\n",
    "2. Se usássemos `fit_transform` nos dados de teste também, e digamos que nesses últimos 3 meses houve um pico de calor e a temperatura foi de 0°C a 40°C, o scaler \"aprenderia\" essa nova faixa de valores. Isso seria problemático porque a escala de normalização dos dados de treinamento e teste seria diferente, levando a inconsistências.\n",
    "\n",
    "Por isso, ao usar apenas `transform` nos dados de teste, garantimos que eles são ajustados à mesma escala dos dados de treinamento, usando os valores mínimos e máximos aprendidos a partir do conjunto de treinamento.\n",
    "\n",
    "**Analogia**: Imagine que você está ajustando o tamanho de fotos para caber em um álbum. Se você decidir que todas as fotos devem ter 10x10cm com base nas primeiras fotos, é importante manter esse tamanho para todas as outras, mesmo que algumas das fotos originais sejam maiores ou menores. O `fit` é como decidir o tamanho com base nas primeiras fotos, e o `transform` é como cortar ou ampliar as outras fotos para esse tamanho decidido.\n",
    "\n",
    "\n",
    "### 4.4 Quando usar a normalização?\n",
    "\n",
    "- **Atributos**: Normalmente, queremos normalizar atributos que têm escalas muito diferentes, para garantir que todos tenham o mesmo peso no modelo.\n",
    "\n",
    "- **Classe Alvo (y)**: Em tarefas de regressão, é comum normalizar a variável alvo, especialmente quando os algoritmos dependem da magnitude. No entanto, em tarefas de classificação, não normalizamos a variável alvo, pois geralmente é categórica.\n",
    "\n",
    "**Nota**: Sempre se lembre de reverter a normalização da variável alvo (se aplicado) para obter previsões na escala original. (iremos ver nas próximas aulas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa a biblioteca para normalizar os dados com Min Max \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Cria um ainstância do normalizador\n",
    "normalizador = MinMaxScaler()\n",
    "\n",
    "# Normaliza o X_train e aprende quais são os valores mínimos e máximos de cada coluna de X\n",
    "X_train = normalizador.fit_transform(X_train)\n",
    "\n",
    "# Normaliza o X_trest com os valores mínimos e máximos de cada coluna de X do X_train\n",
    "X_test = normalizador.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora já estamos lidando com matrizes numpy\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício\n",
    "Importe a biblioteca  pandas\n",
    "\n",
    "Realize a leitura da base de dados 'campanha_marketing.csv'\n",
    "\n",
    "Verifique o tipo de dados das colunas\n",
    "\n",
    "Verifique os valores das colunas object (Textuais)\n",
    "\n",
    "Utilize os métodos de conversão de textos para números adequados para cada coluna textual (Caso necessaŕio, importe a biblioteca LabelEncoder)\n",
    "\n",
    "Separe os dados em X e y\n",
    "\n",
    "Separe em X e y de treinamento e teste com 25% para teste\n",
    "\n",
    "Normalize X de treinamento\n",
    "\n",
    "Normalize X de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f43ba6cefd8f24580ff42e8af3aabb69fa421e7aad4e479f4a62a25e10b01fe1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
